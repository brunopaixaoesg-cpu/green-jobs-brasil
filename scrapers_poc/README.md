# ü§ñ POC - Scraper de Vagas ESG

## üìã Objetivo

Proof of Concept para **web scraping autom√°tico** de vagas ESG/Sustentabilidade em plataformas de emprego brasileiras.

## üéØ Escopo do POC

### Sites-alvo (Fase 1):
1. ‚úÖ **Vagas.com** - API p√∫blica dispon√≠vel
2. ‚è≥ **LinkedIn Jobs** - Requer autentica√ß√£o
3. ‚è≥ **Catho** - HTML parsing
4. ‚è≥ **Indeed** - API dispon√≠vel

### Palavras-chave ESG:
- Sustentabilidade
- ESG
- Meio Ambiente
- ODS
- Energia Renov√°vel
- Reciclagem
- Carbon Neutral
- Green
- Ambiental

## üèóÔ∏è Estrutura

```
scrapers_poc/
‚îú‚îÄ‚îÄ README.md              # Este arquivo
‚îú‚îÄ‚îÄ requirements.txt       # Depend√™ncias Python
‚îú‚îÄ‚îÄ config.py             # Configura√ß√µes e keywords
‚îú‚îÄ‚îÄ base_scraper.py       # Classe base abstrata
‚îú‚îÄ‚îÄ vagas_com_scraper.py  # Scraper Vagas.com
‚îú‚îÄ‚îÄ test_scraper.py       # Script de teste
‚îî‚îÄ‚îÄ results/              # Resultados salvos (JSON)
    ‚îî‚îÄ‚îÄ .gitkeep
```

## üöÄ Como Usar

### 1. Instalar depend√™ncias

```bash
cd scrapers_poc
pip install -r requirements.txt
```

### 2. Executar teste

```bash
python test_scraper.py
```

### 3. Ver resultados

Os resultados s√£o salvos em `results/vagas_YYYY-MM-DD_HH-MM-SS.json`

## üìä Estrutura de Dados

Cada vaga extra√≠da cont√©m:

```json
{
  "titulo": "Analista de Sustentabilidade",
  "empresa": "Empresa Verde Ltda",
  "localizacao": "S√£o Paulo - SP",
  "tipo": "CLT",
  "remoto": true,
  "descricao": "Descri√ß√£o completa da vaga...",
  "requisitos": "Requisitos extra√≠dos...",
  "salario": "R$ 6.000 - R$ 9.000",
  "link_candidatura": "https://vagas.com/exemplo",
  "fonte": "vagas.com",
  "data_scraping": "2025-10-11T21:05:00",
  "keywords_encontradas": ["sustentabilidade", "ESG", "ODS 13"]
}
```

## ‚úÖ Crit√©rios de Sucesso do POC

- [ ] Consegue extrair **m√≠nimo 10 vagas** de Vagas.com
- [ ] Taxa de sucesso > 80% (vagas v√°lidas)
- [ ] Tempo de execu√ß√£o < 2 minutos
- [ ] Identifica corretamente palavras-chave ESG
- [ ] Formato de dados compat√≠vel com `vagas_esg` table

## üîÑ Pr√≥ximos Passos (P√≥s-POC)

Se aprovado:

1. **Integra√ß√£o com projeto principal**
   - Mover para `Empresas Verdes/scrapers/`
   - Integrar com banco `gjb_dev.db`
   - Adicionar colunas: `origem`, `link_externo`, `scraped_at`

2. **Classifica√ß√£o autom√°tica ODS**
   - Usar OpenAI GPT-4 para classificar vagas
   - Extrair habilidades ESG do texto
   - Score de autenticidade (anti-greenwashing)

3. **Automa√ß√£o**
   - APScheduler para rodar a cada 6 horas
   - Dashboard de monitoramento
   - Email com resumo di√°rio

4. **Escalabilidade**
   - Adicionar mais sites (LinkedIn, Catho, Indeed)
   - Proxy rotation (evitar bloqueio)
   - Rate limiting

## ‚ö†Ô∏è Limita√ß√µes Conhecidas

- **Anti-scraping**: Sites podem bloquear ap√≥s muitas requisi√ß√µes
- **HTML din√¢mico**: Alguns sites requerem JavaScript (Playwright)
- **Manuten√ß√£o**: HTML muda, scraper quebra (precisa monitoramento)
- **Legal**: Verificar ToS de cada site

## üìù Decis√£o

**Bruno deve avaliar:**
- ‚úÖ Qualidade das vagas extra√≠das
- ‚úÖ Quantidade suficiente para MVP
- ‚úÖ Complexidade de manuten√ß√£o
- ‚úÖ Risco de bloqueio

**Depois decidir:**
- üü¢ Integrar no projeto principal
- üü° Melhorar POC antes
- üî¥ Descartar e buscar alternativa (APIs pagas)

---

**Data:** 2025-10-11  
**Status:** üöß Em desenvolvimento  
**Respons√°vel:** GitHub Copilot + Bruno
