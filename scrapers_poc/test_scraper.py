"""
Script de teste para o POC de Scraper de Vagas ESG

Executa scraping no Vagas.com e salva resultados
"""
import sys
from vagas_com_scraper import VagasComScraper
import config

def main():
    """Executa teste do scraper"""
    
    print("="*70)
    print("ğŸ¤– POC - SCRAPER DE VAGAS ESG")
    print("="*70)
    print(f"\nğŸ“ Fonte: Vagas.com")
    print(f"ğŸ”‘ Keywords: {len(config.ESG_KEYWORDS)}")
    print(f"ğŸ¯ Meta: {config.MAX_VAGAS_PER_RUN} vagas\n")
    
    # Confirmar execuÃ§Ã£o
    resposta = input("Deseja continuar? (s/n): ").strip().lower()
    if resposta != 's':
        print("âŒ OperaÃ§Ã£o cancelada")
        return
    
    print("\n" + "="*70)
    
    # Inicializar scraper
    scraper = VagasComScraper()
    
    # Executar scraping
    try:
        vagas = scraper.extrair_todas_vagas(max_vagas=config.MAX_VAGAS_PER_RUN)
        
        # Mostrar resumo
        scraper.imprimir_resumo()
        
        # Salvar resultados
        if vagas:
            arquivo = scraper.salvar_resultados()
            print(f"\nâœ… Scraping concluÃ­do com sucesso!")
            print(f"ğŸ“ Arquivo salvo: {arquivo}")
            print(f"ğŸ“Š Total de vagas: {len(vagas)}\n")
            
            # Perguntar se quer ver detalhes de algumas vagas
            ver_detalhes = input("\nDeseja buscar detalhes completos das 5 primeiras vagas? (s/n): ").strip().lower()
            if ver_detalhes == 's':
                links = [v.get('link_candidatura') for v in vagas[:5] if v.get('link_candidatura')]
                if links:
                    vagas_detalhadas = scraper.buscar_vagas_detalhadas(links)
                    
                    print("\n" + "="*70)
                    print("ğŸ“‹ DETALHES DAS VAGAS")
                    print("="*70 + "\n")
                    
                    for i, vaga in enumerate(vagas_detalhadas, 1):
                        print(f"\n{i}. {vaga.get('titulo', 'Sem tÃ­tulo')}")
                        print(f"   {'â”€'*60}")
                        print(f"   ğŸ¢ Empresa: {vaga.get('empresa', 'N/A')}")
                        print(f"   ğŸ“ Local: {vaga.get('localizacao', 'N/A')}")
                        print(f"   ğŸ’¼ Tipo: {vaga.get('tipo', 'N/A')}")
                        print(f"   ğŸ  Remoto: {'Sim' if vaga.get('remoto') else 'NÃ£o'}")
                        if vaga.get('salario'):
                            print(f"   ğŸ’° SalÃ¡rio: {vaga['salario']}")
                        print(f"   ğŸ”— Link: {vaga.get('link_candidatura', 'N/A')}")
                        
                        if vaga.get('descricao'):
                            desc = vaga['descricao'][:200] + "..." if len(vaga.get('descricao', '')) > 200 else vaga.get('descricao', '')
                            print(f"\n   ğŸ“ DescriÃ§Ã£o:\n   {desc}\n")
        else:
            print("\nâš ï¸ Nenhuma vaga encontrada. PossÃ­veis razÃµes:")
            print("   - Site mudou estrutura HTML")
            print("   - Keywords nÃ£o retornaram resultados")
            print("   - Bloqueio anti-scraping")
            print("   - Problema de conexÃ£o\n")
    
    except KeyboardInterrupt:
        print("\n\nâ¸ï¸ Scraping interrompido pelo usuÃ¡rio")
        print(f"ğŸ“Š Vagas coletadas atÃ© agora: {len(scraper.vagas)}")
        
        if scraper.vagas:
            salvar = input("\nDeseja salvar os resultados parciais? (s/n): ").strip().lower()
            if salvar == 's':
                arquivo = scraper.salvar_resultados()
                print(f"ğŸ’¾ Resultados parciais salvos em: {arquivo}\n")
    
    except Exception as e:
        print(f"\nâŒ Erro inesperado: {str(e)}")
        import traceback
        traceback.print_exc()
    
    finally:
        print("\n" + "="*70)
        print("ğŸ Teste finalizado")
        print("="*70 + "\n")

if __name__ == "__main__":
    main()
